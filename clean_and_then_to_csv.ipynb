{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from functools import partial\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/edwardkim/Documents/Galvanize/DSI/NBA-LBJ-vs-MJ-Capstone1\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all CSVs for LBJ and MJ reg season stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/edwardkim/Documents/Galvanize/DSI/NBA-LBJ-vs-MJ-Capstone1/data/Michael\")\n",
    "\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames], sort=False)\n",
    "combined_csv.to_csv(\"combined_Michael.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/edwardkim/Documents/Galvanize/DSI/NBA-LBJ-vs-MJ-Capstone1/data/Lebron\")\n",
    "\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames], sort=False)\n",
    "combined_csv.to_csv(\"combined_Lebron.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "mj_df = pd.read_csv('data/mj_comb_szn_stats_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbj_df = pd.read_csv('data/lbj_comb_szn_stats_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Unneccessary Columns from lbj_df and mj_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up and format LBJ and MJ df's\n",
    "- Clean up rows that are repeated headers\n",
    "- Convert `Date` column into datetime format\n",
    "- Drop `Unnamed: 0` column from both df's\n",
    "- Drop other unneccessary columns from lbj_df and mj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbj_df['Date'] = lbj_df['Date'].apply(pd.to_datetime, format='%Y-%m-%d')\n",
    "mj_df['Date'] = mj_df['Date'].apply(pd.to_datetime, format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbj_df.sort_values('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#DO NOT RUN AGAIN\n",
    "\n",
    "mj_df.rename(columns={mj_df.columns[0]: \"drop1\"}, inplace=True)\n",
    "lbj_df.rename(columns={lbj_df.columns[0]: \"drop1\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['drop1', 'G', 'Date', 'Age', 'WL', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
      "       '3PA', '3P%', 'FT', 'FTA', 'FT%', 'TRB', 'AST', 'STL', 'BLK', 'TOV',\n",
      "       'PTS', 'GmSc', '+/-'],\n",
      "      dtype='object')\n",
      "Index(['drop1', 'G', 'Date', 'Age', 'WL', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
      "       '3PA', '3P%', 'FT', 'FTA', 'FT%', 'TRB', 'AST', 'STL', 'BLK', 'TOV',\n",
      "       'PTS', 'GmSc', '+/-'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(lbj_df.columns)\n",
    "print(mj_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NaN column\n",
    "mj_df.drop(columns=['drop1', 'G', 'MP', '+/-', '3P%', 'FT%'], inplace=True)\n",
    "lbj_df.drop(columns=['drop1', 'G', 'MP', '+/-', '3P%', 'FT%'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Age', 'WL', 'FG', 'FGA', 'FG%', '3P', '3PA', 'FT', 'FTA', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PTS', 'GmSc']\n"
     ]
    }
   ],
   "source": [
    "lbj_cols = list(lbj_df.columns)\n",
    "print(lbj_cols)\n",
    "    \n",
    "num_cols = ['FG', 'Age', 'FGA', 'FG%', '3P', '3PA', 'FT',\n",
    "            'FTA', 'TRB', 'AST', 'STL', 'BLK',\n",
    "            'TOV', 'PTS', 'GmSc']\n",
    "\n",
    "lbj_df[num_cols] = lbj_df[num_cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "mj_df[num_cols] = mj_df[num_cols].apply(pd.to_numeric, errors='coerce', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Date, Age, WL, FG, FGA, FG%, 3P, 3PA, FT, FTA, TRB, AST, STL, BLK, TOV, PTS, GmSc]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Date, Age, WL, FG, FGA, FG%, 3P, 3PA, FT, FTA, TRB, AST, STL, BLK, TOV, PTS, GmSc]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#Checking for rows with NaN values\n",
    "\n",
    "is_NaN = mj_df.isnull()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "rows_with_NaN = mj_df[row_has_NaN]\n",
    "print(rows_with_NaN)\n",
    "\n",
    "is_NaN = lbj_df.isnull()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "rows_with_NaN = lbj_df[row_has_NaN]\n",
    "print(rows_with_NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### GmSc - Game Score; the formula is PTS + 0.4 * FG - 0.7 * FGA - 0.4*(FTA - FT) + 0.7 * ORB + 0.3 * DRB + STL + 0.7 * AST + 0.7 * BLK - 0.4 * PF - TOV. Game Score was created by John Hollinger to give a rough measure of a player's productivity for a single game. The scale is similar to that of points scored, (40 is an outstanding performance, 10 is an average performance, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save cleaned data to CSV (lbj_df and mj_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbj_df.to_csv(\"final_lbj_comb_szn_stats.csv\")\n",
    "mj_df.to_csv(\"final_mj_comb_szn_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postseason Stats for Lebron and Michael\n",
    "- Change \"{year} Playoffs\" column to \"Date\"\n",
    "- Remove rows that are repeated headers\n",
    "- Convert applicable columns into `numeric`, date into `datetime` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbj_ps_df = pd.read_csv(\"data/Lebron_postseason.csv\")\n",
    "mj_ps_df = pd.read_csv(\"data/Michael_postseason.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBJ Index(['Unnamed: 0', 'Rk', 'G', '2006 Playoffs', 'Series', 'Tm', ' ', 'Opp',\n",
      "       'G#', ' .1', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', 'FT',\n",
      "       'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
      "       'PTS', 'GmSc', '+/-'],\n",
      "      dtype='object')\n",
      "MJ Index(['Unnamed: 0', 'Rk', 'G', '1985 Playoffs', 'Series', 'Tm', ' ', 'Opp',\n",
      "       'G#', ' .1', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', 'FT',\n",
      "       'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
      "       'PTS', 'GmSc'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 283 entries, 0 to 282\n",
      "Data columns (total 32 columns):\n",
      "Unnamed: 0       283 non-null int64\n",
      "Rk               251 non-null object\n",
      "G                251 non-null object\n",
      "2006 Playoffs    251 non-null object\n",
      "Series           251 non-null object\n",
      "Tm               251 non-null object\n",
      "                 130 non-null object\n",
      "Opp              251 non-null object\n",
      "G#               251 non-null object\n",
      " .1              251 non-null object\n",
      "GS               251 non-null object\n",
      "MP               251 non-null object\n",
      "FG               251 non-null object\n",
      "FGA              251 non-null object\n",
      "FG%              251 non-null object\n",
      "3P               251 non-null object\n",
      "3PA              251 non-null object\n",
      "3P%              247 non-null object\n",
      "FT               251 non-null object\n",
      "FTA              251 non-null object\n",
      "FT%              249 non-null object\n",
      "ORB              251 non-null object\n",
      "DRB              251 non-null object\n",
      "TRB              251 non-null object\n",
      "AST              251 non-null object\n",
      "STL              251 non-null object\n",
      "BLK              251 non-null object\n",
      "TOV              251 non-null object\n",
      "PF               251 non-null object\n",
      "PTS              251 non-null object\n",
      "GmSc             251 non-null object\n",
      "+/-              251 non-null object\n",
      "dtypes: int64(1), object(31)\n",
      "memory usage: 70.9+ KB\n"
     ]
    }
   ],
   "source": [
    "print(\"LBJ\", lbj_ps_df.columns)\n",
    "print(\"MJ\", mj_ps_df.columns)\n",
    "\n",
    "lbj_ps_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#gets rid of first 2 columns which are just index columns, gets rid of unnecessary columns\n",
    "\n",
    "mj_ps_df.rename(columns={mj_ps_df.columns[6]: \"drop1\", mj_ps_df.columns[9]: \"WL\"}, inplace=True)\n",
    "lbj_ps_df.rename(columns={lbj_ps_df.columns[6]: 'drop1', lbj_ps_df.columns[9]: \"WL\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lbj_ps_df.drop(columns=lbj_ps_df.columns[0:2], inplace=True)\n",
    "lbj_ps_df.drop(columns=['Tm', 'Opp', 'G#', 'GS', 'MP', 'ORB', 'DRB', 'PF',\n",
    "                        'G', 'Series', 'drop1','3P%', 'FT%'], inplace=True)\n",
    "\n",
    "mj_ps_df.drop(columns=mj_ps_df.columns[0:2], inplace=True)\n",
    "mj_ps_df.drop(columns=['Tm', 'Opp', 'G#', 'GS', 'MP', 'ORB', 'DRB', 'PF',\n",
    "                      'G', 'Series', 'drop1','3P%', 'FT%'], inplace=True)\n",
    "\n",
    "lbj_ps_df = lbj_ps_df.rename(columns={'2006 Playoffs': \"Date\"})\n",
    "mj_ps_df = mj_ps_df.rename(columns={\"1985 Playoffs\": \"Date\"})\n",
    "\n",
    "#Get rid of empty rows\n",
    "lbj_ps_df = lbj_ps_df[pd.notnull(lbj_ps_df[\"Date\"])]\n",
    "mj_ps_df = mj_ps_df[pd.notnull(mj_ps_df[\"Date\"])]\n",
    "\n",
    "#Convert \"WL\" column into a simple format: W or L\n",
    "lbj_ps_df[\"WL\"] = lbj_ps_df.apply(lambda x: x[\"WL\"][0], axis=1)\n",
    "mj_ps_df[\"WL\"] = mj_ps_df.apply(lambda x: x[\"WL\"][0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'WL', 'FG', 'FGA', 'FG%', '3P', '3PA', 'FT', 'FTA', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PTS', 'GmSc', '+/-']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardkim/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "/Users/edwardkim/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/edwardkim/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#Turn values to numeric and get rid of rows that are repeated headers\n",
    "\n",
    "lbj_ps_df = lbj_ps_df[lbj_ps_df.FT != 'FT']\n",
    "mj_ps_df = mj_ps_df[mj_ps_df.FT != 'FT']\n",
    "    \n",
    "num_cols_lbj = ['FG', 'FGA', 'FG%', '3P', '3PA', 'FT', 'FTA',\n",
    "            'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PTS', 'GmSc', '+/-']\n",
    "\n",
    "#mj does not have the '+/-' column\n",
    "num_cols_mj = ['FG', 'FGA', 'FG%', '3P', '3PA', 'FT', 'FTA',\n",
    "            'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PTS', 'GmSc']\n",
    "\n",
    "lbj_ps_df[num_cols_lbj] = lbj_ps_df[num_cols_lbj].apply(pd.to_numeric, errors='ignore', axis=1)\n",
    "mj_ps_df[num_cols_mj] = mj_ps_df[num_cols_mj].apply(pd.to_numeric, errors='ignore', axis=1)\n",
    "\n",
    "lbj_ps_df['Date'] = lbj_ps_df['Date'].apply(pd.to_datetime, format='%Y-%m-%d')\n",
    "mj_ps_df['Date'] = mj_ps_df['Date'].apply(pd.to_datetime, format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MJ_PS Empty DataFrame\n",
      "Columns: [Date, WL, FG, FGA, FG%, 3P, 3PA, FT, FTA, TRB, AST, STL, BLK, TOV, PTS, GmSc]\n",
      "Index: []\n",
      "LBJ_PS Empty DataFrame\n",
      "Columns: [Date, WL, FG, FGA, FG%, 3P, 3PA, FT, FTA, TRB, AST, STL, BLK, TOV, PTS, GmSc, +/-]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#Check for rows in ps_df's\n",
    "\n",
    "is_NaN = mj_ps_df.isnull()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "rows_with_NaN = mj_ps_df[row_has_NaN]\n",
    "print(\"MJ_PS\", rows_with_NaN)\n",
    "\n",
    "is_NaN = lbj_ps_df.isnull()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "rows_with_NaN = lbj_ps_df[row_has_NaN]\n",
    "print(\"LBJ_PS\",rows_with_NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbj_ps_df.to_csv(\"final_lbj_ps_cleaned.csv\")\n",
    "mj_ps_df.to_csv(\"final_mj_ps_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Stats and Reg Season Stats For All Players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add \"Year\" column to each season csv to be able to differentiate duplicate player entries\n",
    "- Sort file list so that the correct year is assigned to each CSV\n",
    "- Once column is added, save as new csv and then concatenate into csv --> pd df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['year_col_added_advanced_all_players_1985.csv', 'year_col_added_advanced_all_players_1986.csv', 'year_col_added_advanced_all_players_1987.csv', 'year_col_added_advanced_all_players_1988.csv', 'year_col_added_advanced_all_players_1989.csv', 'year_col_added_advanced_all_players_1990.csv', 'year_col_added_advanced_all_players_1991.csv', 'year_col_added_advanced_all_players_1992.csv', 'year_col_added_advanced_all_players_1993.csv', 'year_col_added_advanced_all_players_1995.csv', 'year_col_added_advanced_all_players_1996.csv', 'year_col_added_advanced_all_players_1997.csv', 'year_col_added_advanced_all_players_1998.csv', 'year_col_added_advanced_all_players_2002.csv', 'year_col_added_advanced_all_players_2003.csv', 'year_col_added_advanced_all_players_2004.csv', 'year_col_added_advanced_all_players_2005.csv', 'year_col_added_advanced_all_players_2006.csv', 'year_col_added_advanced_all_players_2007.csv', 'year_col_added_advanced_all_players_2008.csv', 'year_col_added_advanced_all_players_2009.csv', 'year_col_added_advanced_all_players_2010.csv', 'year_col_added_advanced_all_players_2011.csv', 'year_col_added_advanced_all_players_2012.csv', 'year_col_added_advanced_all_players_2013.csv', 'year_col_added_advanced_all_players_2014.csv', 'year_col_added_advanced_all_players_2015.csv', 'year_col_added_advanced_all_players_2016.csv', 'year_col_added_advanced_all_players_2017.csv', 'year_col_added_advanced_all_players_2018.csv', 'year_col_added_advanced_all_players_2019.csv']\n",
      "31\n",
      "[1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1995, 1996, 1997, 1998, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/Users/edwardkim/Documents/Galvanize/DSI/NBA-LBJ-vs-MJ-Capstone1/data/advanced_stats\")\n",
    "\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "all_filenames.sort()\n",
    "print(all_filenames)\n",
    "print(len(all_filenames))\n",
    "\n",
    "years = list(range(1985, 1994))\n",
    "years.extend(list(range(1995, 1999)))\n",
    "years.extend(list(range(2002, 2020)))\n",
    "print(years)\n",
    "print(len(years))\n",
    "\n",
    "for i,j in zip(all_filenames, years):\n",
    "    df = pd.read_csv(i)\n",
    "    df[\"Year\"] = int(j)\n",
    "    df.to_csv(f\"year_col_added_{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate the CSVs and read them into PD DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/edwardkim/Documents/Galvanize/DSI/NBA-LBJ-vs-MJ-Capstone1/data/reg_season_stats\")\n",
    "\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames], sort=False)\n",
    "combined_csv.to_csv(\"reg_szn_85-19.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/edwardkim/Documents/Galvanize/DSI/NBA-LBJ-vs-MJ-Capstone1/data/advanced_stats\")\n",
    "\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames], sort=False)\n",
    "combined_csv.to_csv(\"adv_szn_85-19.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/edwardkim/Documents/Galvanize/DSI/NBA-LBJ-vs-MJ-Capstone1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_df = pd.read_csv('data/advanced_stats/adv_szn_85-19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "szn_df = pd.read_csv('data/reg_season_stats/reg_szn_85-19.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert applicable rows to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_cols = adv_df.columns\n",
    "adv_cols\n",
    "    \n",
    "num_cols = ['Age','G', 'MP', 'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', \n",
    "            'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS',\n",
    "            'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP']\n",
    "\n",
    "adv_df[num_cols] = adv_df[num_cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "\n",
    "#gets rid of first 2 columns that are just indices\n",
    "adv_df.drop(columns=adv_df.columns[:2], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows that are repeated headers and unneccessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "szn_cols = szn_df.columns\n",
    "\n",
    "num_cols = ['Age','G', 'GS', 'MP', 'FG',\n",
    "            'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT',\n",
    "            'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
    "            'PTS']\n",
    "\n",
    "szn_df[num_cols] = szn_df[num_cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "\n",
    "#gets rid of first 2 columns that are just indices\n",
    "szn_df.drop(columns=szn_df.columns[:2], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a \"GmSc\" column\n",
    "szn_df[\"GmSc\"] = szn_df['PTS'] + 0.4*szn_df['FG'] - 0.7*szn_df['FGA'] - 0.4*(szn_df['FTA'] - szn_df['FT']) + 0.7*szn_df['ORB'] + 0.3*szn_df['DRB'] + szn_df['STL'] + 0.7*szn_df['AST'] + 0.7*szn_df['BLK'] - 0.4*szn_df['PF'] - szn_df['TOV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%',\n",
       "       '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%',\n",
       "       'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Year',\n",
       "       'GmSc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "szn_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "szn_drop_cols = ['Tm', 'GS', 'MP', '3P%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB','PF']\n",
    "adv_drop_cols = ['MP','3PAr', 'FTr','ORB%', 'DRB%','OBPM', 'DBPM']\n",
    "\n",
    "szn_df.drop(columns=szn_drop_cols, inplace=True)\n",
    "adv_df.drop(columns=adv_drop_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'PER', 'TS%', 'TRB%', 'AST%',\n",
       "       'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'BPM',\n",
       "       'VORP', 'Year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_df.drop(columns=adv_df.columns[-4], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_df.drop(columns=adv_df.columns[-8], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_df = adv_df[adv_df.Rk != 'Rk']\n",
    "szn_df = szn_df[szn_df.Rk != 'Rk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16451 entries, 0 to 17102\n",
      "Data columns (total 22 columns):\n",
      "Rk        16451 non-null object\n",
      "Player    16451 non-null object\n",
      "Pos       16451 non-null object\n",
      "Age       16451 non-null float64\n",
      "G         16451 non-null float64\n",
      "FG        16451 non-null float64\n",
      "FGA       16451 non-null float64\n",
      "FG%       16369 non-null float64\n",
      "3P        16451 non-null float64\n",
      "3PA       16451 non-null float64\n",
      "2P        16451 non-null float64\n",
      "2PA       16451 non-null float64\n",
      "2P%       16319 non-null float64\n",
      "eFG%      16369 non-null float64\n",
      "TRB       16451 non-null float64\n",
      "AST       16451 non-null float64\n",
      "STL       16451 non-null float64\n",
      "BLK       16451 non-null float64\n",
      "TOV       16451 non-null float64\n",
      "PTS       16451 non-null float64\n",
      "Year      16451 non-null int64\n",
      "GmSc      16451 non-null float64\n",
      "dtypes: float64(18), int64(1), object(3)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "szn_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save cleaned datasets as csv\n",
    "\n",
    "adv_df.to_csv(\"final_adv_data_cleaned.csv\")\n",
    "szn_df.to_csv(\"final_szn_data_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

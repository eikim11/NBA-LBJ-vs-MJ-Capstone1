{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from functools import partial\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/edwardkim/Documents/Galvanize/DSI/NBA-LBJ-vs-MJ-Capstone1\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all CSVs for LBJ and MJ reg season stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/edwardkim/Documents/Galvanize/DSI/NBA-LBJ-vs-MJ-Capstone1/data/Michael\")\n",
    "\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames], sort=False)\n",
    "combined_csv.to_csv(\"combined_Michael.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/edwardkim/Documents/Galvanize/DSI/NBA-LBJ-vs-MJ-Capstone1/data/Lebron\")\n",
    "\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames], sort=False)\n",
    "combined_csv.to_csv(\"combined_Lebron.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "mj_df = pd.read_csv('data/mj_comb_szn_stats_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbj_df = pd.read_csv('data/lbj_comb_szn_stats_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Unneccessary Columns from lbj_df and mj_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up and format LBJ and MJ df's\n",
    "- Clean up rows that are repeated headers\n",
    "- Convert `Date` column into datetime format\n",
    "- Drop `Unnamed: 0` column from both df's\n",
    "- Drop other unneccessary columns from lbj_df and mj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbj_df['Date'] = lbj_df['Date'].apply(pd.to_datetime, format='%Y-%m-%d')\n",
    "mj_df['Date'] = mj_df['Date'].apply(pd.to_datetime, format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbj_df.sort_values('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#DO NOT RUN AGAIN\n",
    "\n",
    "mj_df.rename(columns={mj_df.columns[0]: \"drop1\"}, inplace=True)\n",
    "lbj_df.rename(columns={lbj_df.columns[0]: \"drop1\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['drop1', 'G', 'Date', 'Age', 'WL', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
      "       '3PA', '3P%', 'FT', 'FTA', 'FT%', 'TRB', 'AST', 'STL', 'BLK', 'TOV',\n",
      "       'PTS', 'GmSc', '+/-'],\n",
      "      dtype='object')\n",
      "Index(['drop1', 'G', 'Date', 'Age', 'WL', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
      "       '3PA', '3P%', 'FT', 'FTA', 'FT%', 'TRB', 'AST', 'STL', 'BLK', 'TOV',\n",
      "       'PTS', 'GmSc', '+/-'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(lbj_df.columns)\n",
    "print(mj_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NaN column\n",
    "mj_df.drop(columns=['drop1', 'G', 'MP', '+/-', '3P%', 'FT%'], inplace=True)\n",
    "lbj_df.drop(columns=['drop1', 'G', 'MP', '+/-', '3P%', 'FT%'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Age', 'WL', 'FG', 'FGA', 'FG%', '3P', '3PA', 'FT', 'FTA', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PTS', 'GmSc']\n"
     ]
    }
   ],
   "source": [
    "lbj_cols = list(lbj_df.columns)\n",
    "print(lbj_cols)\n",
    "    \n",
    "num_cols = ['FG', 'Age', 'FGA', 'FG%', '3P', '3PA', 'FT',\n",
    "            'FTA', 'TRB', 'AST', 'STL', 'BLK',\n",
    "            'TOV', 'PTS', 'GmSc']\n",
    "\n",
    "lbj_df[num_cols] = lbj_df[num_cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "mj_df[num_cols] = mj_df[num_cols].apply(pd.to_numeric, errors='coerce', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Date, Age, WL, FG, FGA, FG%, 3P, 3PA, FT, FTA, TRB, AST, STL, BLK, TOV, PTS, GmSc]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Date, Age, WL, FG, FGA, FG%, 3P, 3PA, FT, FTA, TRB, AST, STL, BLK, TOV, PTS, GmSc]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#Checking for rows with NaN values\n",
    "\n",
    "is_NaN = mj_df.isnull()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "rows_with_NaN = mj_df[row_has_NaN]\n",
    "print(rows_with_NaN)\n",
    "\n",
    "is_NaN = lbj_df.isnull()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "rows_with_NaN = lbj_df[row_has_NaN]\n",
    "print(rows_with_NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### GmSc - Game Score; the formula is PTS + 0.4 * FG - 0.7 * FGA - 0.4*(FTA - FT) + 0.7 * ORB + 0.3 * DRB + STL + 0.7 * AST + 0.7 * BLK - 0.4 * PF - TOV. Game Score was created by John Hollinger to give a rough measure of a player's productivity for a single game. The scale is similar to that of points scored, (40 is an outstanding performance, 10 is an average performance, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save cleaned data to CSV (lbj_df and mj_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbj_df.to_csv(\"final_lbj_comb_szn_stats.csv\")\n",
    "mj_df.to_csv(\"final_mj_comb_szn_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postseason Stats for Lebron and Michael\n",
    "- Change \"{year} Playoffs\" column to \"Date\"\n",
    "- Remove rows that are repeated headers\n",
    "- Convert applicable columns into `numeric`, date into `datetime` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbj_ps_df = pd.read_csv(\"data/Lebron_postseason.csv\")\n",
    "mj_ps_df = pd.read_csv(\"data/Michael_postseason.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBJ Index(['Unnamed: 0', 'Rk', 'G', '2006 Playoffs', 'Series', 'Tm', ' ', 'Opp',\n",
      "       'G#', ' .1', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', 'FT',\n",
      "       'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
      "       'PTS', 'GmSc', '+/-'],\n",
      "      dtype='object')\n",
      "MJ Index(['Unnamed: 0', 'Rk', 'G', '1985 Playoffs', 'Series', 'Tm', ' ', 'Opp',\n",
      "       'G#', ' .1', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', 'FT',\n",
      "       'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
      "       'PTS', 'GmSc'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 283 entries, 0 to 282\n",
      "Data columns (total 32 columns):\n",
      "Unnamed: 0       283 non-null int64\n",
      "Rk               251 non-null object\n",
      "G                251 non-null object\n",
      "2006 Playoffs    251 non-null object\n",
      "Series           251 non-null object\n",
      "Tm               251 non-null object\n",
      "                 130 non-null object\n",
      "Opp              251 non-null object\n",
      "G#               251 non-null object\n",
      " .1              251 non-null object\n",
      "GS               251 non-null object\n",
      "MP               251 non-null object\n",
      "FG               251 non-null object\n",
      "FGA              251 non-null object\n",
      "FG%              251 non-null object\n",
      "3P               251 non-null object\n",
      "3PA              251 non-null object\n",
      "3P%              247 non-null object\n",
      "FT               251 non-null object\n",
      "FTA              251 non-null object\n",
      "FT%              249 non-null object\n",
      "ORB              251 non-null object\n",
      "DRB              251 non-null object\n",
      "TRB              251 non-null object\n",
      "AST              251 non-null object\n",
      "STL              251 non-null object\n",
      "BLK              251 non-null object\n",
      "TOV              251 non-null object\n",
      "PF               251 non-null object\n",
      "PTS              251 non-null object\n",
      "GmSc             251 non-null object\n",
      "+/-              251 non-null object\n",
      "dtypes: int64(1), object(31)\n",
      "memory usage: 70.9+ KB\n"
     ]
    }
   ],
   "source": [
    "print(\"LBJ\", lbj_ps_df.columns)\n",
    "print(\"MJ\", mj_ps_df.columns)\n",
    "\n",
    "lbj_ps_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#gets rid of first 2 columns which are just index columns, gets rid of unnecessary columns\n",
    "\n",
    "mj_ps_df.rename(columns={mj_ps_df.columns[6]: \"drop1\", mj_ps_df.columns[9]: \"WL\"}, inplace=True)\n",
    "lbj_ps_df.rename(columns={lbj_ps_df.columns[6]: 'drop1', lbj_ps_df.columns[9]: \"WL\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lbj_ps_df.drop(columns=lbj_ps_df.columns[0:2], inplace=True)\n",
    "lbj_ps_df.drop(columns=['Tm', 'Opp', 'G#', 'GS', 'MP', 'ORB', 'DRB', 'PF',\n",
    "                        'G', 'Series', 'drop1','3P%', 'FT%'], inplace=True)\n",
    "\n",
    "mj_ps_df.drop(columns=mj_ps_df.columns[0:2], inplace=True)\n",
    "mj_ps_df.drop(columns=['Tm', 'Opp', 'G#', 'GS', 'MP', 'ORB', 'DRB', 'PF',\n",
    "                      'G', 'Series', 'drop1','3P%', 'FT%'], inplace=True)\n",
    "\n",
    "lbj_ps_df = lbj_ps_df.rename(columns={'2006 Playoffs': \"Date\"})\n",
    "mj_ps_df = mj_ps_df.rename(columns={\"1985 Playoffs\": \"Date\"})\n",
    "\n",
    "#Get rid of empty rows\n",
    "lbj_ps_df = lbj_ps_df[pd.notnull(lbj_ps_df[\"Date\"])]\n",
    "mj_ps_df = mj_ps_df[pd.notnull(mj_ps_df[\"Date\"])]\n",
    "\n",
    "#Convert \"WL\" column into a simple format: W or L\n",
    "lbj_ps_df[\"WL\"] = lbj_ps_df.apply(lambda x: x[\"WL\"][0], axis=1)\n",
    "mj_ps_df[\"WL\"] = mj_ps_df.apply(lambda x: x[\"WL\"][0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'WL', 'FG', 'FGA', 'FG%', '3P', '3PA', 'FT', 'FTA', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PTS', 'GmSc', '+/-']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardkim/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "/Users/edwardkim/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/edwardkim/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#Turn values to numeric and get rid of rows that are repeated headers\n",
    "\n",
    "lbj_ps_df = lbj_ps_df[lbj_ps_df.FT != 'FT']\n",
    "mj_ps_df = mj_ps_df[mj_ps_df.FT != 'FT']\n",
    "    \n",
    "num_cols_lbj = ['FG', 'FGA', 'FG%', '3P', '3PA', 'FT', 'FTA',\n",
    "            'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PTS', 'GmSc', '+/-']\n",
    "\n",
    "#mj does not have the '+/-' column\n",
    "num_cols_mj = ['FG', 'FGA', 'FG%', '3P', '3PA', 'FT', 'FTA',\n",
    "            'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PTS', 'GmSc']\n",
    "\n",
    "lbj_ps_df[num_cols_lbj] = lbj_ps_df[num_cols_lbj].apply(pd.to_numeric, errors='ignore', axis=1)\n",
    "mj_ps_df[num_cols_mj] = mj_ps_df[num_cols_mj].apply(pd.to_numeric, errors='ignore', axis=1)\n",
    "\n",
    "lbj_ps_df['Date'] = lbj_ps_df['Date'].apply(pd.to_datetime, format='%Y-%m-%d')\n",
    "mj_ps_df['Date'] = mj_ps_df['Date'].apply(pd.to_datetime, format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MJ_PS Empty DataFrame\n",
      "Columns: [Date, WL, FG, FGA, FG%, 3P, 3PA, FT, FTA, TRB, AST, STL, BLK, TOV, PTS, GmSc]\n",
      "Index: []\n",
      "LBJ_PS Empty DataFrame\n",
      "Columns: [Date, WL, FG, FGA, FG%, 3P, 3PA, FT, FTA, TRB, AST, STL, BLK, TOV, PTS, GmSc, +/-]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#Check for rows in ps_df's\n",
    "\n",
    "is_NaN = mj_ps_df.isnull()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "rows_with_NaN = mj_ps_df[row_has_NaN]\n",
    "print(\"MJ_PS\", rows_with_NaN)\n",
    "\n",
    "is_NaN = lbj_ps_df.isnull()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "rows_with_NaN = lbj_ps_df[row_has_NaN]\n",
    "print(\"LBJ_PS\",rows_with_NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbj_ps_df.to_csv(\"final_lbj_ps_cleaned.csv\")\n",
    "mj_ps_df.to_csv(\"final_mj_ps_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Stats and Reg Season Stats For All Players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add \"Year\" column to each season csv to be able to differentiate duplicate player entries\n",
    "- Sort file list so that the correct year is assigned to each CSV\n",
    "- Once column is added, save as new csv and then concatenate into csv --> pd df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['advanced_all_players_1985.csv', 'advanced_all_players_1986.csv', 'advanced_all_players_1987.csv', 'advanced_all_players_1988.csv', 'advanced_all_players_1989.csv', 'advanced_all_players_1990.csv', 'advanced_all_players_1991.csv', 'advanced_all_players_1992.csv', 'advanced_all_players_1993.csv', 'advanced_all_players_1995.csv', 'advanced_all_players_1996.csv', 'advanced_all_players_1997.csv', 'advanced_all_players_1998.csv', 'advanced_all_players_2002.csv', 'advanced_all_players_2003.csv', 'advanced_all_players_2004.csv', 'advanced_all_players_2005.csv', 'advanced_all_players_2006.csv', 'advanced_all_players_2007.csv', 'advanced_all_players_2008.csv', 'advanced_all_players_2009.csv', 'advanced_all_players_2010.csv', 'advanced_all_players_2011.csv', 'advanced_all_players_2012.csv', 'advanced_all_players_2013.csv', 'advanced_all_players_2014.csv', 'advanced_all_players_2015.csv', 'advanced_all_players_2016.csv', 'advanced_all_players_2017.csv', 'advanced_all_players_2018.csv', 'advanced_all_players_2019.csv']\n",
      "31\n",
      "[1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1995, 1996, 1997, 1998, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/Users/edwardkim/Documents/Galvanize/DSI/NBA-LBJ-vs-MJ-Capstone1/data/advanced_stats\")\n",
    "\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "all_filenames.sort()\n",
    "print(all_filenames)\n",
    "print(len(all_filenames))\n",
    "\n",
    "years = list(range(1985, 1994))\n",
    "years.extend(list(range(1995, 1999)))\n",
    "years.extend(list(range(2002, 2020)))\n",
    "print(years)\n",
    "print(len(years))\n",
    "\n",
    "for i,j in zip(all_filenames, years):\n",
    "    df = pd.read_csv(i)\n",
    "    df[\"Year\"] = int(j)\n",
    "    df.to_csv(f\"year_col_added_{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate the CSVs and read them into PD DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/edwardkim/Documents/Galvanize/DSI/NBA-LBJ-vs-MJ-Capstone1/data/reg_season_stats\")\n",
    "\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames], sort=False)\n",
    "combined_csv.to_csv(\"reg_szn_85-19.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/edwardkim/Documents/Galvanize/DSI/NBA-LBJ-vs-MJ-Capstone1/data/advanced_stats\")\n",
    "\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames], sort=False)\n",
    "combined_csv.to_csv(\"adv_szn_85-19.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/edwardkim/Documents/Galvanize/DSI/NBA-LBJ-vs-MJ-Capstone1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_df = pd.read_csv('data/adv_szn_85-19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "szn_df = pd.read_csv('data/reg_szn_85-19.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert applicable rows to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_cols = adv_df.columns\n",
    "adv_cols\n",
    "    \n",
    "num_cols = ['Age','G', 'MP', 'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', \n",
    "            'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS',\n",
    "            'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP']\n",
    "\n",
    "adv_df[num_cols] = adv_df[num_cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "\n",
    "#gets rid of first 2 columns that are just indices\n",
    "adv_df.drop(columns=adv_df.columns[:2], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows that are repeated headers and unneccessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "szn_cols = szn_df.columns\n",
    "\n",
    "num_cols = ['Age','G', 'GS', 'MP', 'FG',\n",
    "            'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT',\n",
    "            'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
    "            'PTS']\n",
    "\n",
    "szn_df[num_cols] = szn_df[num_cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "\n",
    "#gets rid of first 2 columns that are just indices\n",
    "szn_df.drop(columns=szn_df.columns[:2], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "szn_drop_cols = ['Tm', 'G', 'GS', 'MP', '3P%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB','PF']\n",
    "adv_drop_cols = ['G', 'MP','3PAr', 'FTr','ORB%', 'DRB%','OBPM', 'DBPM']\n",
    "\n",
    "szn_df.drop(columns=szn_drop_cols, inplace=True)\n",
    "adv_df.drop(columns=adv_drop_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_df = adv_df[adv_df.Rk != 'Rk']\n",
    "szn_df = szn_df[szn_df.Rk != 'Rk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>TRB%</th>\n",
       "      <th>AST%</th>\n",
       "      <th>STL%</th>\n",
       "      <th>BLK%</th>\n",
       "      <th>TOV%</th>\n",
       "      <th>USG%</th>\n",
       "      <th>OWS</th>\n",
       "      <th>DWS</th>\n",
       "      <th>WS</th>\n",
       "      <th>WS/48</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>16451.000000</td>\n",
       "      <td>16446.000000</td>\n",
       "      <td>16377.000000</td>\n",
       "      <td>16446.000000</td>\n",
       "      <td>16446.000000</td>\n",
       "      <td>16446.000000</td>\n",
       "      <td>16446.000000</td>\n",
       "      <td>16390.000000</td>\n",
       "      <td>16446.000000</td>\n",
       "      <td>16451.000000</td>\n",
       "      <td>16451.000000</td>\n",
       "      <td>16451.000000</td>\n",
       "      <td>16446.000000</td>\n",
       "      <td>16451.000000</td>\n",
       "      <td>16451.000000</td>\n",
       "      <td>16451.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>26.783539</td>\n",
       "      <td>12.412733</td>\n",
       "      <td>0.507541</td>\n",
       "      <td>9.955278</td>\n",
       "      <td>13.003363</td>\n",
       "      <td>1.629612</td>\n",
       "      <td>1.490417</td>\n",
       "      <td>14.588401</td>\n",
       "      <td>18.810799</td>\n",
       "      <td>1.204808</td>\n",
       "      <td>1.151334</td>\n",
       "      <td>2.356860</td>\n",
       "      <td>0.066138</td>\n",
       "      <td>-2.007914</td>\n",
       "      <td>0.548186</td>\n",
       "      <td>2004.030272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>4.039713</td>\n",
       "      <td>6.361054</td>\n",
       "      <td>0.097603</td>\n",
       "      <td>5.136947</td>\n",
       "      <td>9.569756</td>\n",
       "      <td>1.055115</td>\n",
       "      <td>1.813167</td>\n",
       "      <td>6.877246</td>\n",
       "      <td>5.470249</td>\n",
       "      <td>2.012653</td>\n",
       "      <td>1.193484</td>\n",
       "      <td>2.925724</td>\n",
       "      <td>0.103254</td>\n",
       "      <td>9.363892</td>\n",
       "      <td>1.302455</td>\n",
       "      <td>10.327880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>-54.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.300000</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-2.100000</td>\n",
       "      <td>-1.365000</td>\n",
       "      <td>-1000.000000</td>\n",
       "      <td>-2.100000</td>\n",
       "      <td>1985.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>0.476000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>10.900000</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>-3.700000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>1995.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>13.700000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>-1.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>17.700000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>17.100000</td>\n",
       "      <td>22.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2013.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>133.800000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>24.900000</td>\n",
       "      <td>77.800000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>83.600000</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>21.200000</td>\n",
       "      <td>2.712000</td>\n",
       "      <td>242.200000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>2019.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age           PER           TS%          TRB%          AST%  \\\n",
       "count  16451.000000  16446.000000  16377.000000  16446.000000  16446.000000   \n",
       "mean      26.783539     12.412733      0.507541      9.955278     13.003363   \n",
       "std        4.039713      6.361054      0.097603      5.136947      9.569756   \n",
       "min       18.000000    -54.400000      0.000000      0.000000      0.000000   \n",
       "25%       24.000000      9.600000      0.476000      6.000000      6.200000   \n",
       "50%       26.000000     12.600000      0.520000      9.000000     10.200000   \n",
       "75%       29.000000     15.600000      0.555000     13.300000     17.700000   \n",
       "max       44.000000    133.800000      1.500000    100.000000    100.000000   \n",
       "\n",
       "               STL%          BLK%          TOV%          USG%           OWS  \\\n",
       "count  16446.000000  16446.000000  16390.000000  16446.000000  16451.000000   \n",
       "mean       1.629612      1.490417     14.588401     18.810799      1.204808   \n",
       "std        1.055115      1.813167      6.877246      5.470249      2.012653   \n",
       "min        0.000000      0.000000      0.000000      0.000000     -3.300000   \n",
       "25%        1.100000      0.400000     10.900000     15.200000      0.000000   \n",
       "50%        1.500000      0.900000     13.700000     18.500000      0.400000   \n",
       "75%        2.000000      2.000000     17.100000     22.100000      1.800000   \n",
       "max       24.900000     77.800000    100.000000     83.600000     15.200000   \n",
       "\n",
       "                DWS            WS         WS/48           BPM          VORP  \\\n",
       "count  16451.000000  16451.000000  16446.000000  16451.000000  16451.000000   \n",
       "mean       1.151334      2.356860      0.066138     -2.007914      0.548186   \n",
       "std        1.193484      2.925724      0.103254      9.363892      1.302455   \n",
       "min       -0.600000     -2.100000     -1.365000  -1000.000000     -2.100000   \n",
       "25%        0.200000      0.200000      0.031000     -3.700000     -0.100000   \n",
       "50%        0.800000      1.300000      0.076000     -1.600000      0.000000   \n",
       "75%        1.700000      3.600000      0.115000      0.400000      0.800000   \n",
       "max        9.100000     21.200000      2.712000    242.200000     12.500000   \n",
       "\n",
       "               Year  \n",
       "count  16451.000000  \n",
       "mean    2004.030272  \n",
       "std       10.327880  \n",
       "min     1985.000000  \n",
       "25%     1995.000000  \n",
       "50%     2006.000000  \n",
       "75%     2013.000000  \n",
       "max     2019.000000  "
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save cleaned datasets as csv\n",
    "\n",
    "adv_df.to_csv(\"final_adv_data_cleaned.csv\")\n",
    "szn_df.to_csv(\"final_szn_data_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
